import os
import cv2
import torch
import random
import albumentations as A
from tqdm import tqdm
from torchvision import models, transforms as T
from PIL import Image, ImageEnhance


# 1. ë°ê¸° ë¶„ë¥˜ê¸° ë¡œë“œ
def load_brightness_classifier(model_path, device):
    model = models.resnet18(weights=None)  # êµ¬ì¡°ë§Œ ë¡œë“œ
    model.fc = torch.nn.Linear(model.fc.in_features, 3)  # s1/s3/s5
    model.load_state_dict(torch.load(model_path, map_location=device))
    model = model.to(device)
    model.eval()
    return model



# 2. ì´ë¯¸ì§€ â†’ ë°ê¸° ë‹¨ê³„ ì˜ˆì¸¡
def predict_stage(model, img, device):
    tf = T.Compose([
        T.Resize((224, 224)),
        T.ToTensor(),
        T.Normalize(mean=[0.485, 0.456, 0.406],
                    std=[0.229, 0.224, 0.225])
    ])
    x = tf(img).unsqueeze(0).to(device)
    with torch.no_grad():
        pred = model(x).argmax(1).item()
    return ["s1", "s3", "s5"][pred]

# 3. ë‹¨ê³„ë³„ ë°ê¸° ì¦ê°•
def brightness_stage_augment(img, stage):

    def gamma(img, g):
        inv = 1.0 / g
        table = [int((i / 255.0) ** inv * 255) for i in range(256)]
        if img.mode == "RGB":
            table = table * 3
        return img.point(table)

    # Stage 1: ë°ê²Œ (ì €ì¡°ë„ ë³´ì™„ ë°©í–¥)
    if stage == "s1":
        img = gamma(img, random.uniform(1.05, 1.12))
        img = ImageEnhance.Contrast(img).enhance(random.uniform(1.00, 1.08))

    # Stage 3: ì¤‘ê°„ ë‹¨ê³„ (ë°ê¸° ë³€í™” ìµœì†Œ + ìƒ‰ê° ë³€í™”)
    elif stage == "s3":
        img = gamma(img, random.uniform(0.98, 1.02))
        img = ImageEnhance.Color(img).enhance(random.uniform(0.95, 1.05))

    # Stage 5: ì €ì¡°ë„ ë‹¨ê³„ (ì•ˆì „í•œ ì–´ë‘¡ê¸°)
    else:
        img = gamma(img, random.uniform(0.92, 0.98))
        img = ImageEnhance.Brightness(img).enhance(random.uniform(0.92, 1.02))

    return img



# 4. YOLOìš© ê¸°ë³¸ ì¦ê°•
def get_yolo_augment():
    return A.Compose([
        A.HorizontalFlip(p=0.5),
        A.Rotate(limit=7, p=0.5),
        A.Resize(640, 640)
    ], bbox_params=A.BboxParams(
        format='yolo',
        label_fields=['class_labels'],
        min_visibility=0.2,
        clip=True
    ))


# 5. ì‹¤í–‰ íŒŒì´í”„ë¼ì¸ (trainë§Œ ìˆ˜í–‰)
if __name__ == "__main__":

    # ===== ì…ë ¥ ê²½ë¡œ =====
    src_img_dir = r"E:/aihub_lowlight/balanced_scene_split/train/images"
    src_lbl_dir = r"E:/aihub_lowlight/balanced_scene_split/train/labels"

    # ===== ì¶œë ¥ ê²½ë¡œ =====
    dst_img_dir = r"E:/aihub_lowlight/dataset/brightness_stage_aug_1202/train/images"
    dst_lbl_dir = r"E:/aihub_lowlight/dataset/brightness_stage_aug_1202/train/labels"

    # ë¶„ë¥˜ê¸° ê²½ë¡œ
    model_path = r"E:/aihub_lowlight/brightness_stage_classifier.pt"

    # ì¶œë ¥ í´ë” ìƒì„±
    os.makedirs(dst_img_dir, exist_ok=True)
    os.makedirs(dst_lbl_dir, exist_ok=True)

    # ì¥ì¹˜ ì„ íƒ
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"í˜„ì¬ ì¥ì¹˜: {device}")

    # ëª¨ë¸/ì¦ê°•ê¸° ë¶ˆëŸ¬ì˜¤ê¸°
    model = load_brightness_classifier(model_path, device)
    yolo_tf = get_yolo_augment()

    
    # ì´ë¯¸ì§€ ë‹¨ì¼ í´ë”ì—ì„œ ë°”ë¡œ ì²˜ë¦¬ 
    print("\n brightness augmentation ì‹¤í–‰ ì¤‘...")

    for fname in tqdm(os.listdir(src_img_dir), desc="Train ì¦ê°• ì§„í–‰ ì¤‘"):
        if not fname.lower().endswith((".jpg", ".jpeg", ".png")):
            continue

        img_path = os.path.join(src_img_dir, fname)
        lbl_path = os.path.join(src_lbl_dir, fname.replace(".jpg", ".txt"))
        dst_img_path = os.path.join(dst_img_dir, fname)
        dst_lbl_path = os.path.join(dst_lbl_dir, fname.replace(".jpg", ".txt"))

        # ì´ë¯¸ì§€ ë¡œë“œ
        image = cv2.imread(img_path)
        if image is None or not os.path.exists(lbl_path):
            continue

        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        # ë¼ë²¨ ì½ê¸°
        with open(lbl_path, "r") as f:
            lines = [x.strip().split() for x in f.readlines() if len(x.strip()) > 0]
        if len(lines) == 0:
            continue

        bboxes = [[float(x[1]), float(x[2]), float(x[3]), float(x[4])] for x in lines]
        class_labels = [int(x[0]) for x in lines]

        # YOLO ì¦ê°•
        transformed = yolo_tf(image=image, bboxes=bboxes, class_labels=class_labels)
        aug_img = transformed['image']
        aug_boxes = transformed['bboxes']
        aug_labels = transformed['class_labels']

        # PIL ë³€í™˜
        pil_img = Image.fromarray(aug_img)

        # ë°ê¸° ë‹¨ê³„ ì˜ˆì¸¡ + ì¦ê°•
        stage = predict_stage(model, pil_img, device)
        pil_img = brightness_stage_augment(pil_img, stage)

        # ì €ì¥
        pil_img.save(dst_img_path)

        with open(dst_lbl_path, "w") as f:
            for cls, (x, y, w, h) in zip(aug_labels, aug_boxes):
                f.write(f"{cls} {x:.6f} {y:.6f} {w:.6f} {h:.6f}\n")

    print("\nğŸ‰ brightness_stage_aug_1206 â†’ Train ì¦ê°• ì™„ë£Œ!")
    print("ì´ë¯¸ì§€:", dst_img_dir)
    print("ë¼ë²¨:", dst_lbl_dir)
